{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Global': 1, 'Netflix': 1, 'HBO Max': 1, 'Paramount+': 1, 'TVE': 0, 'Hulu': 0, 'Rai 1': 0, 'CTV': 0, 'Syfy': 0, 'AMC': 0, 'TF1': 0, 'ZDF': 0, 'Citytv': 0, 'Disney+': 0, 'CraveTV': 0, 'NBC': 0, 'BBC One': 0, 'BET': 0, 'Apple TV+': 0, 'France 2': 0, 'Nickelodeon': 0, 'Channel 5': 0, 'ALLBLK': 0, 'BET+': 0, 'Moviestar+': 0, 'OCS': 0, 'SundanceTV': 0, 'Amazon Freevee': 0, 'Showtime': 0, 'Prime Video': 0, 'Starz': 0, 'TV4': 0, 'OWN': 0, 'Één': 0, 'Radio Canada': 0, 'The Comedy Network': 0, 'TBS (US)': 0, 'Canal+': 0, 'Acorn TV': 0, 'CBC': 0, 'Showtime on Demand': 0, 'Epix': 0, 'Fox': 0, 'ATRESplayer': 0, 'TMC': 0, 'Adult Swim': 0, 'CBC Gem': 0, 'HBO': 0, 'BBC iPlayer': 0, 'Puhu TV': 0, 'Sky1': 0, 'France 3': 0, 'FX': 0}\n",
      "{'Netflix': 4, 'Hulu': 3, 'TF1': 3, 'Disney+': 3, 'NBC': 3, 'France 2': 3, 'TVE': 2, 'BET': 2, 'Channel 5': 2, 'Paramount+': 2, 'Rai 1': 1, 'CTV': 1, 'Syfy': 1, 'AMC': 1, 'ZDF': 1, 'Citytv': 1, 'CraveTV': 1, 'Global': 1, 'BBC One': 1, 'Apple TV+': 1, 'Nickelodeon': 1, 'ALLBLK': 1, 'HBO Max': 1, 'BET+': 1, 'Moviestar+': 1, 'OCS': 1, 'SundanceTV': 1, 'Amazon Freevee': 1, 'Showtime': 1, 'Prime Video': 1, 'Starz': 1, 'TV4': 1, 'OWN': 1, 'Één': 1, 'Radio Canada': 1, 'The Comedy Network': 1, 'TBS (US)': 1, 'Canal+': 1, 'Acorn TV': 1, 'CBC': 1, 'Showtime on Demand': 1, 'Epix': 1, 'Fox': 1, 'ATRESplayer': 1, 'TMC': 1, 'Adult Swim': 1, 'CBC Gem': 1, 'HBO': 1, 'BBC iPlayer': 1, 'Puhu TV': 1, 'Sky1': 1, 'France 3': 1, 'FX': 1}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "# 1️⃣ Récupérer les données relatives à la diffusion d’épisodes pour le mois en cours disponibles sur cette page :  \n",
    "def get_series(year_month = \"\"):\n",
    "    url = f\"https://www.spin-off.fr/calendrier_des_series.html?date={year_month}\"\n",
    "\n",
    "    # Request Content\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "\n",
    "    # Parse HTML\n",
    "    page = BeautifulSoup(content, features=\"html.parser\")\n",
    "\n",
    "\n",
    "    list_of_series = [serie_name for serie_name in page.find_all('span',class_=['calendrier_episodes'])]\n",
    "\n",
    "    # Le nom de la série\n",
    "    list_of_series_name = [serie_name.find_all(\"a\")[0].text for serie_name in list_of_series]\n",
    "\n",
    "    # Le numéro de l’épisode\n",
    "    list_of_series_episode = [serie_episode.find_all(\"a\")[1].text.split(\".\")[1] for serie_episode in list_of_series]\n",
    "\n",
    "    # Le numéro de la saison\n",
    "    list_of_series_season = [serie_season.find_all(\"a\")[1].text.split(\".\")[0] for serie_season in list_of_series]\n",
    "\n",
    "    # La date de diffusion de l’épisode\n",
    "    list_of_series_date = [serie_date.find_previous_sibling(\"div\").get(\"id\").strip(\"jour_\") for serie_date in list_of_series]\n",
    "\n",
    "    # Le pays d’origine\n",
    "    list_of_series_origin = [serie_origin.find_previous_sibling().find_previous_sibling().get(\"alt\") for serie_origin in list_of_series]\n",
    "\n",
    "    # La chaîne qui diffuse la série\n",
    "    list_of_series_channel = [serie_channel.find_previous_sibling().get(\"alt\") for serie_channel in list_of_series]\n",
    "\n",
    "    # L’url relative de la page de l’épisode sur le site spin-off \n",
    "    # (par exemple : episode01-408094-01102023-saison14-Bob-s-Burgers.html)\n",
    "    list_of_series_url = [serie_url.find_all(\"a\")[1].get('href') for serie_url in list_of_series]\n",
    "\n",
    "    # print(list_of_series)\n",
    "    # print(\"Le nom de la série (\", len(list_of_series_name), \") : \", list_of_series_name)\n",
    "    # print(\"Le numéro de l’épisode (\", len(list_of_series_episode), \") : \", list_of_series_episode)\n",
    "    # print(\"Le numéro de la saison (\", len(list_of_series_season), \") : \", list_of_series_season)\n",
    "    # print(\"La date de diffusion de l’épisode (\", len(list_of_series_origin), \") : \", list_of_series_origin)\n",
    "    # print(\"Le pays d’origine (\", len(list_of_series_channel), \") : \", list_of_series_channel)\n",
    "    # print(\"La chaîne qui diffuse la série (\", len(list_of_series_date), \") : \", list_of_series_date)\n",
    "    # print(\"L’url relative de la page de l’épisode sur le site spin-off  (\", len(list_of_series_url), \") : \", list_of_series_url)\n",
    "\n",
    "    return {\n",
    "        \"nom_serie\": list_of_series_name, \n",
    "        \"numero_de_lepisode\": list_of_series_episode, \n",
    "        \"numero_de_la_saison\": list_of_series_season, \n",
    "        \"date_de_diffusion_de_lepisode\": list_of_series_date, \n",
    "        \"pays_d_origine\": list_of_series_origin, \n",
    "        \"chaine_de_diffusion\": list_of_series_channel, \n",
    "        \"url_relative_de_lepisode\": list_of_series_url\n",
    "    }\n",
    "# print(get_series())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1️⃣ Enregistrez ces données dans un fichier episodes.csv dans le dossier data/files (vous pouvez utiliser une librairie) :\n",
    "def create_episode_csv(data):\n",
    "    header = [key for key in data]    \n",
    "    data_values = [data[key] for key in data]\n",
    "    \n",
    "    rows = []\n",
    "    # On parcourt la liste (sachant que chaque liste a la même longueur)\n",
    "    for column in range(len(data_values[0])):\n",
    "        row = []\n",
    "        for index in range(len(data_values)):\n",
    "            row.append(data_values[index][column])\n",
    "        rows.append(row)\n",
    "        \n",
    "    with open('data/files/episodes.csv', 'w+') as file:\n",
    "        file.write(\",\".join(header))\n",
    "        for row in rows:\n",
    "            file.write(\"\\n\" + \",\".join(row))\n",
    "            \n",
    "# create_episode_csv(get_series())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3️⃣ Écrire une fonction ou une classe qui permet de lire le fichier episodes.csv sans utiliser de librairie. Cette fonction ou classe devra renvoyer une liste de tuples avec les bons types : \n",
    "def read_episodes_csv():       \n",
    "    with open('data/files/episodes.csv', 'r') as file:\n",
    "        content = file.read()\n",
    "        typed_content = []\n",
    "        for serie in content.split(\"\\n\")[1:]:\n",
    "            serie_elements = serie.split(\",\")            \n",
    "            \n",
    "            # Épisodes\n",
    "            if serie_elements[1]:\n",
    "                if serie_elements[1].isalpha():\n",
    "                    serie_elements[1] = -1\n",
    "                else:\n",
    "                    serie_elements[1] = (int(serie_elements[1]))\n",
    "                    \n",
    "            # Saisons  \n",
    "            if serie_elements[2]:\n",
    "                if serie_elements[2].isalpha():\n",
    "                    serie_elements[2] = 0\n",
    "                else:\n",
    "                    serie_elements[2] = (int(serie_elements[2]))\n",
    "                    \n",
    "            # Date de diffusion  \n",
    "            if serie_elements[3]:\n",
    "                serie_date = serie_elements[3].split(\"-\")\n",
    "                year = int(serie_date[2])\n",
    "                month = int(serie_date[1])\n",
    "                day = int(serie_date[0])\n",
    "                serie_elements[3] = date(year, month, day)\n",
    "                    \n",
    "            typed_content.append(tuple(serie_row for serie_row in serie_elements))\n",
    "        return typed_content\n",
    "            \n",
    "# print(read_episodes_csv())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SQL [1/2]\n",
    "# 2️⃣ Insérer les données de la question Scraping [1/2] dans base de données sqlite appelée database.db dans le dossier data/databases. La table devra s’appeler episode .\n",
    "# Veillez à utiliser les types adéquats (la date peut toutefois être stockée en tant que chaîne de caractères avec un typeTEXT).\n",
    "def episodes_to_database():\n",
    "    # Connexion à la base de données (si elle n'existe pas, elle sera créée)\n",
    "    conn = sqlite3.connect('data/databases/database.db')\n",
    "\n",
    "    # Création d'un curseur pour exécuter des commandes SQL\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Définition du schéma de la table\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS episode (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            nom_serie TEXT,\n",
    "            numero_episode INTEGER,\n",
    "            numero_saison INTEGER,\n",
    "            date_diffusion DATE,\n",
    "            pays_origine TEXT,\n",
    "            chaine_diffusion TEXT,\n",
    "            url_episode TEXT\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Insérer les données\n",
    "    cur.executemany(\"\"\"INSERT INTO episode \n",
    "                    (\n",
    "                        nom_serie,\n",
    "                        numero_episode,\n",
    "                        numero_saison,\n",
    "                        date_diffusion,\n",
    "                        pays_origine,\n",
    "                        chaine_diffusion,\n",
    "                        url_episode\n",
    "                    ) VALUES (?,?,?,?,?,?,?)\"\"\",\n",
    "                    read_episodes_csv())\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Décommenter ci-dessous pour tester la lecture\n",
    "    cur.execute(\"SELECT * FROM episode\")\n",
    "    resultats = cur.fetchall()\n",
    "    for row in resultats:\n",
    "        print(row)\n",
    "\n",
    "# episodes_to_database()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Refacto Functions\n",
    "def count(property_name, reverse = True, sort = True):\n",
    "    counts = {}\n",
    "    for element in property_name:\n",
    "        if element in counts:\n",
    "            counts[element] += 1\n",
    "        else:\n",
    "            counts[element] = 1\n",
    "    if sort == True:\n",
    "        return dict(sorted(counts.items(), key=lambda item: item[1], reverse=reverse))\n",
    "    else:\n",
    "        return counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Algorithmie [1/2]\n",
    "# 3️⃣ Calculer le nombre d’épisodes diffusés par chaque chaîne de télévision (présente dans les données) en Octobre.\n",
    "# property_name → \"nom_serie\", \"numero_de_lepisode\", \"numero_de_la_saison\", \"date_de_diffusion_de_lepisode\", \"pays_d_origine\", \"chaine_de_diffusion\", \"url_relative_de_lepisode\"\n",
    "def count_episodes_by_property(year_month, property_name):\n",
    "    properties = get_series(year_month)[property_name]\n",
    "    return count(properties)\n",
    "\n",
    "# print(count_episodes_by_property(\"2023-10\", \"chaine_de_diffusion\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Vous pouvez faire directement des requêtes SQL, ou rapatrier les données depuis une table (ou un fichier dans lequel vous les auriez stocker) et faire les calculs avec Python. \n",
    "# Indiquer dans le fichier README.md le nom des trois chaînes qui ont diffusé le plus d’épisodes. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3️⃣ Faire de même pour les pays (pensez à mutualiser votre code !)\n",
    "# print(count_episodes_by_property(\"2023-10\", \"pays_d_origine\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3️⃣ Quels mots reviennent le plus souvent dans les noms des séries ? (attention à ne compter qu’une seule fois chaque série, et pas une fois chaque épisode)\n",
    "# Les indiquer dans le fichier README.md\n",
    "def most_used_word_in_show_title():\n",
    "    shows_title = [key for key in count_episodes_by_property(\"2023-10\", \"nom_serie\")]\n",
    "    words = []\n",
    "    for show_title in shows_title:\n",
    "        for word in show_title.split(\" \"):\n",
    "            words.append(word.upper())\n",
    "    \n",
    "    # return (next(iter(count(words))))\n",
    "    return count(words)\n",
    "\n",
    "# print(most_used_word_in_show_title())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scraping [2/2] \n",
    "# 4️⃣ Sur les pages individuelles des épisodes (dont l’url à été récupérée lors de la première question), récupérer la durée de l’épisode. Les requêtes peuvent être un peu longue donc vous pouvez ne le faire que pour une seule chaîne comme Apple TV. Veiller à ne pas perdre les données pour pouvoir les insérer dans SQL. Pensez à utiliser un time.sleep entre les requêtes.\n",
    "def get_episodes_duration():\n",
    "    # Connexion à la base de données (si elle n'existe pas, elle sera créée)\n",
    "    conn = sqlite3.connect('data/databases/database.db')\n",
    "\n",
    "    # Création d'un curseur pour exécuter des commandes SQL\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM episode WHERE chaine_diffusion LIKE 'Apple TV+'\")\n",
    "    series = cur.fetchall()\n",
    "\n",
    "    durations = []\n",
    "    for serie in series:    \n",
    "        url = f\"https://www.spin-off.fr/{serie[7]}\"\n",
    "\n",
    "        # Request Content\n",
    "        response = requests.get(url)\n",
    "        content = response.content\n",
    "\n",
    "        # Parse HTML\n",
    "        page = BeautifulSoup(content, features=\"html.parser\")\n",
    "        duration = page.find('div', class_='episode_infos_episode_format').text.replace(\"minutes\", \"\").strip()\n",
    "        \n",
    "        if duration != \"\":\n",
    "            durations.append([serie[0], int(duration)])\n",
    "        else:\n",
    "            durations.append([serie[0], 0])\n",
    "            \n",
    "        \n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "    return durations\n",
    "        \n",
    "# print(get_episodes_duration())\n",
    "\n",
    "\n",
    "\n",
    "# SQL [2/2]\n",
    "# 4️⃣ Stocker les données de durée d’épisode (en minutes) dans une nouvelles table duration qui contiendra une Foreign Key pointant sur l’épisode en question dans la table episode \n",
    "def save_duration_to_database():\n",
    "    # Connexion à la base de données (si elle n'existe pas, elle sera créée)\n",
    "    conn = sqlite3.connect('data/databases/database.db')\n",
    "\n",
    "    # Création d'un curseur pour exécuter des commandes SQL\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Définition du schéma de la table\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS duration (\n",
    "            id   INTEGER PRIMARY KEY,\n",
    "            duration INTEGER,\n",
    "            duration_id INTEGER,\n",
    "            FOREIGN KEY (duration_id)\n",
    "                REFERENCES episode (id) \n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Insérer les données\n",
    "    cur.executemany(\"\"\"INSERT INTO duration \n",
    "                    (\n",
    "                        duration_id,\n",
    "                        duration\n",
    "                    ) VALUES (?,?)\"\"\",\n",
    "                    get_episodes_duration())\n",
    "    conn.commit()\n",
    "    \n",
    "# save_duration_to_database()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Algorithmie [2/2]\n",
    "# 5️⃣ Quelle est la chaîne de TV qui diffuse des épisodes pendant le plus grand nombre de jours consécutifs sur le mois d’Octobre ? (écrire une fonction qui permet de répondre à cet question)\n",
    "# print(count_episodes_by_property(\"2023-10\", \"chaine_de_diffusion\"))\n",
    "def most_diffused_channel(year_month):\n",
    "    url = f\"https://www.spin-off.fr/calendrier_des_series.html?date={year_month}\"\n",
    "\n",
    "    # Request Content\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "\n",
    "    # Parse HTML\n",
    "    page = BeautifulSoup(content, features=\"html.parser\")\n",
    "\n",
    "\n",
    "    # td_jour\n",
    "    # list_of_days = [serie_name.find(\"div\", class_=\"div_jour\").get(\"id\").strip(\"jour_\") for serie_name in page.find_all('td',class_=['td_jour']) if serie_name.find(\"div\", class_=\"div_jour\")]\n",
    "    # # list_of_channels = [serie_name.find(\"img\").get(\"alt\") for serie_name in page.find_all('td',class_=['td_jour']) if serie_name.find(\"div\", class_=\"div_jour\") and serie_name.find(\"img\").get(\"alt\")]\n",
    "    # list_of_channels = []\n",
    "    # for serie_name in page.find_all('td',class_=['td_jour']):\n",
    "    #     if serie_name.find(\"div\", class_=\"div_jour\"):\n",
    "    #         day = serie_name.find(\"div\", class_=\"div_jour\").get(\"id\").strip(\"jour_\")    \n",
    "            \n",
    "    #         channels = []        \n",
    "    #         for channel in serie_name.find_all(\"span\", class_=\"calendrier_episodes\"):\n",
    "    #             channels.append(channel.find_previous_sibling(\"img\").get(\"alt\"))\n",
    "    #         list_of_channels.append([day, count(channels)])\n",
    "\n",
    "    \n",
    "    # return list_of_channels\n",
    "\n",
    "    # list_of_series = [serie_name for serie_name in page.find_all('span',class_=['calendrier_episodes'])]\n",
    "    \n",
    "    \n",
    "    # objectifs\n",
    "    # - Analyser à partir du début chaque chaine de TV sur tous les jours du mois\n",
    "    # - Garder en mémoire le nombre de consécutive de mois le plus grand par chaine de TV\n",
    "    # - Comparer aux autres chaines de TV\n",
    "    \n",
    "    \n",
    "    # 1. Avoir une liste de toutes chaines et regrouper\n",
    "    # 2. Dans chaque jour, parcourir la liste des chaines disponibles du mois et s'il existe, incrémenter dans la liste sinon 0\n",
    "    list_of_channels = [key for key in count(get_series()[\"chaine_de_diffusion\"])]\n",
    "    list_of_days = [serie_name.find(\"div\", class_=\"div_jour\").get(\"id\").strip(\"jour_\") for serie_name in page.find_all('td',class_=['td_jour']) if serie_name.find(\"div\", class_=\"div_jour\")]\n",
    "    list_of_channels_by_day = [[key for key in count([channel.find_previous_sibling(\"img\").get(\"alt\") for channel in serie_name.find_all(\"span\", class_=\"calendrier_episodes\")], False, False)] for serie_name in page.find_all('td',class_=['td_jour']) if serie_name.find(\"div\", class_=\"div_jour\")]\n",
    "    # list_of_channels_by_day = []\n",
    "    \n",
    "    # for serie_name in page.find_all('td',class_=['td_jour']):\n",
    "    #     if serie_name.find(\"div\", class_=\"div_jour\"):\n",
    "    #         for channel in serie_name.find_all(\"span\", class_=\"calendrier_episodes\"):\n",
    "    #             print(channel)\n",
    "    #             print(channel.find_previous_sibling(\"img\").get(\"alt\"))\n",
    "            \n",
    "        #     for key in count([channel.find_previous_sibling(\"img\").get(\"alt\") ], False, False):\n",
    "        #             list_of_channels_by_day.append(key)\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # for serie_name in page.find_all('td',class_=['td_jour']):\n",
    "    #     if serie_name.find(\"div\", class_=\"div_jour\"):\n",
    "            \n",
    "    #         channels = []        \n",
    "    #         for channel in serie_name.find_all(\"span\", class_=\"calendrier_episodes\"):\n",
    "    #             channels.append(channel.find_previous_sibling(\"img\").get(\"alt\"))\n",
    "    #         list_of_channels_by_day.append([key for key in count(channels)])\n",
    "          \n",
    "          \n",
    "    # print(list_of_channels_by_day)\n",
    "    \n",
    "    # counterAll = []\n",
    "    # counter = {}\n",
    "    # for channel in list_of_channels:\n",
    "    #     for list_channel_of_the_day in list_of_channels_by_day:\n",
    "            \n",
    "    #         if channel in list_of_channels and channel in counter:\n",
    "    #             counter[channel] += 1\n",
    "    #         elif channel not in counter:\n",
    "    #             # counterAll.append(counter)\n",
    "    #             counter[channel] = 1\n",
    "    #         else:\n",
    "    #             counterAll.append(counter)\n",
    "    #             counter[channel] += 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # for channel in list_of_channels:\n",
    "    #     for list_channel_of_the_day in list_of_channels_by_day:\n",
    "            \n",
    "    #         if channel in list_channel_of_the_day:\n",
    "    #             if channel in counter:\n",
    "    #                 counter[channel] += 1\n",
    "    #             else:\n",
    "    #                 counterAll.append(counter)\n",
    "    #                 counter[channel] = 1\n",
    "    #         else:\n",
    "    #             counter[channel] = 1\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # for list_channel_of_the_day in list_of_channels_by_day:\n",
    "    #     counterMax = {}\n",
    "    #     for channel in list_channel_of_the_day:\n",
    "    #         # print(channel, counter, list_of_channels)            \n",
    "    #         if channel in list_of_channels and channel in counter:\n",
    "    #             counter[channel] += 1\n",
    "    #         elif channel not in counter:\n",
    "    #             # counterAll.append(counter)\n",
    "    #             counter[channel] = 1\n",
    "    #         else:\n",
    "    #             counterMax[channel] = counter[channel]\n",
    "    #             counter[channel] = 0\n",
    "                \n",
    "    #         for c in counterAll:\n",
    "    #             if c[channel] > counterMax[channel]:\n",
    "    #                 counterMax[channel] = counter[channel]\n",
    "                \n",
    "                \n",
    "    # counterAll.append(counter)\n",
    "                \n",
    "    # county = {} \n",
    "    # for day in range(len(list_of_days)):\n",
    "    #     list_channel_of_the_day = list_of_channels_by_day[day]\n",
    "    #     # print(list_of_channels_by_day[day])\n",
    "        \n",
    "    #     countAll = {}\n",
    "    #     for channel in list_channel_of_the_day:\n",
    "    #         print(day, channel, list_channel_of_the_day)\n",
    "    #         # if channel in list_of_channels and channel in countAll:\n",
    "    #         #     print(channel)\n",
    "    #         #     countAll[channel] += 1\n",
    "    #         # else:\n",
    "    #         #     county[channel] += (countAll[channel])\n",
    "    #         #     countAll[channel] = 1\n",
    "                \n",
    "\n",
    "    # return counter\n",
    "    \n",
    "    all_channels = []\n",
    "    for list_of_channels_of_the_day in list_of_channels_by_day:\n",
    "        for channel_of_the_day in list_of_channels_of_the_day:\n",
    "            all_channels.append(channel_of_the_day)\n",
    "            \n",
    "    all_channels_filtered = [key for key in count(all_channels, False, False)]\n",
    "            \n",
    "    counter_final = {}\n",
    "    counter_tmp = {}\n",
    "    for channel in all_channels_filtered:\n",
    "        counter_final[channel] = 0\n",
    "        counter_tmp[channel] = 0\n",
    "    for list_of_channels_of_the_day in list_of_channels_by_day:\n",
    "        counter = {}\n",
    "        for channel_of_the_day in list_of_channels_of_the_day:\n",
    "            counter[channel_of_the_day] = 0        \n",
    "        for channel in all_channels_filtered:        \n",
    "            if channel in list_of_channels_of_the_day:\n",
    "                counter_tmp[channel] += 1\n",
    "                if counter_tmp[channel] > counter_final[channel]:\n",
    "                    counter_final[channel] = counter_tmp[channel]\n",
    "            else:\n",
    "                counter_tmp[channel] = 0\n",
    "                \n",
    "        \n",
    "        # for channel_of_the_day in list_of_channels_of_the_day:\n",
    "            # print(channel_of_the_day)\n",
    "            # for channel in all_channels_filtered:\n",
    "            #     # if counter_final not in all_channels_filtered and counter_tmp not in all_channels_filtered:\n",
    "            #     #     counter_final[channel] = 0\n",
    "            #     #     counter_tmp[channel] = 0\n",
    "                \n",
    "                \n",
    "            #     print(\"*******************************\")\n",
    "            #     print(\" \")\n",
    "            #     print(counter_tmp[channel_of_the_day])\n",
    "            #     print(channel_of_the_day, channel)\n",
    "                \n",
    "                \n",
    "            #     if channel == channel_of_the_day:\n",
    "            #         counter_tmp[channel_of_the_day] += 1\n",
    "            #     else:\n",
    "            #         counter_tmp[channel_of_the_day] = 0\n",
    "                    \n",
    "                    \n",
    "            #     print(counter_tmp[channel_of_the_day])\n",
    "            #     print(\" \")\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            #     if counter_tmp[channel_of_the_day] > counter_final[channel_of_the_day]:\n",
    "            #         counter_final[channel_of_the_day] = counter_tmp[channel_of_the_day]\n",
    "                # print(\"*******************************\")\n",
    "            \n",
    "            # counter_tmp[channel_of_the_day] += 1\n",
    "    #     print(counter)\n",
    "    # print(counter_tmp)\n",
    "        \n",
    "            \n",
    "  \n",
    "                \n",
    "        \n",
    "    \n",
    "    # return all_channels\n",
    "    # return counter\n",
    "    # return counter_max\n",
    "    # return list_of_channels_by_day\n",
    "    # return counter_tmp\n",
    "    # print(counter_tmp)\n",
    "    # return counter_final\n",
    "    \n",
    "    #  dict(sorted(counts.items(), key=lambda item: item[1], reverse=reverse))\n",
    "    print(dict(sorted(counter_tmp.items(), key=lambda item: item[1], reverse=True)))\n",
    "    return dict(sorted(counter_final.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "print(most_diffused_channel(\"2023-11\"))\n",
    "\n",
    "# Somme des jours cumulé\n",
    "# 5 programmes télévisé d'une chaine de TV par semaine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
