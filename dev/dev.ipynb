{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'THE': 21, 'OF': 4, 'DE': 4, '(2023)': 4, 'ALL': 4, 'AND': 3, 'AT': 2, 'FAMILY': 2, 'TOUT': 2, '(2022)': 2, 'LEGACY': 2, 'GOOD': 2, 'MURDER': 2, 'UN': 2, 'LA': 2, 'SOKO': 2, 'ANDY': 1, 'BAND': 1, 'SPELLBOUND': 1, 'DAILY': 1, 'DOSE': 1, 'SUNSHINE': 1, 'MOMENT': 1, '(CI': 1, 'SHI': 1, 'CI': 1, 'KE)': 1, 'LAW': 1, '(CAN)': 1, 'BLUE': 1, 'EYE': 1, 'SAMURAI': 1, 'FERRY': 1, '-': 1, 'SERIE': 1, 'TERZI': 1, 'CULPRITS': 1, 'VA': 1, 'BIEN': 1, 'OBLITERATED': 1, 'BLACK': 1, 'CAKE': 1, 'INSPIREZ': 1, 'EXPIREZ': 1, 'ROMANCERO': 1, 'BUCCANEERS': 1, 'MASTER': 1, 'CRIMES': 1, 'MAGNUM': 1, 'P.I.': 1, '(2018)': 1, 'SURREALESTATE': 1, 'FRASIER': 1, 'GADIS': 1, 'KRETEK': 1, 'SANTA': 1, 'CLAUSES': 1, 'RAP': 1, 'SH!T': 1, 'JULIA': 1, 'CHUCKY': 1, 'I': 1, 'LEONI': 1, 'DI': 1, 'SICILIA': 1, 'SHETLAND': 1, 'YOUNG': 1, 'DYLAN': 1, 'LIGHT': 1, 'WE': 1, 'CANNOT': 1, 'SEE': 1, 'KINGDOM': 1, 'BUSINESS': 1, 'VANISHING': 1, 'TRIANGLE': 1, 'BOSCH:': 1, 'FELLOW': 1, 'TRAVELERS': 1, 'INVINCIBLE': 1, 'LESSONS': 1, 'IN': 1, 'CHEMISTRY': 1, 'SHINING': 1, 'VALE': 1, 'SOLSIDAN': 1, 'SHIP': 1, 'TRANSPLANT': 1, 'UPLOAD': 1, 'GUY': 1, 'FEAR': 1, 'WALKING': 1, 'DEAD': 1, 'RICK': 1, 'MORTY': 1, 'GILDED': 1, 'AGE': 1, 'SIMPSONS': 1, 'ACTING': 1, 'AMERICAN': 1, 'DAD!': 1, 'IRRATIONAL': 1, 'FOUND': 1, 'A': 1, 'END': 1, 'WORLD': 1, 'ANDERSON': 1, 'SPIDER': 1, 'SILVA': 1, 'DEMAIN': 1, 'NOUS': 1, 'APPARTIENT': 1, 'HOTEL': 1, 'MONDIAL': 1, 'ICI': 1, 'COMMENCE': 1, 'QUANTUM': 1, 'LEAP': 1, 'ROBYN': 1, 'HOOD': 1, 'SISTAS': 1, 'SI': 1, 'GRAND': 1, 'SOLEIL': 1, 'À': 1, 'CARTE': 1, 'MESIAS': 1, 'GOOSEBUMPS': 1, 'LEIPZIG': 1, 'RISE': 1, \"BOB'S\": 1, 'BURGERS': 1, 'HEARTLAND': 1, '(CA)': 1, 'KRAPOPOLIS': 1, 'LES': 1, 'MYSTÈRES': 1, \"L'AMOUR\": 1, 'MURDOCH': 1, 'MYSTERIES': 1, 'BLACKBERRY': 1, 'FOR': 1, 'MANKIND': 1, 'NCIS:': 1, 'SYDNEY': 1, 'CURSE': 1, 'BEACON': 1, '23': 1, 'MONARCH:': 1, 'MONSTERS': 1, 'FARGO': 1, '4': 1, 'ESTRELLAS': 1, 'BLANCA': 1, 'CHILDREN': 1, 'RUIN': 1, 'EVERYTHING': 1, \"COOPER'S\": 1, 'BAR': 1, 'HUDSON': 1, '&': 1, 'REX': 1, 'MORNING': 1, 'SHOW': 1, 'CREATURES': 1, 'GREAT': 1, 'SMALL': 1, '(2020)': 1, 'DOOM': 1, 'PATROL': 1, 'LOKI': 1, 'LT-21': 1, 'POWER': 1, 'BOOK': 1, 'IV:': 1, 'FORCE': 1, 'ENTRE': 1, 'TIERRAS': 1, 'LAWMEN:': 1, 'BASS': 1, 'REEVES': 1, 'SKYMED': 1, \"D'ARGENT\": 1, 'ET': 1, 'SANG': 1, 'POTSDAM': 1, 'OVAL': 1, 'MY': 1, 'DEMON': 1, 'VIRGIN': 1, 'RIVER': 1, 'STAR': 1, 'TREK:': 1, 'LOWER': 1, 'DECKS': 1, 'GEN': 1, 'V': 1, 'BOOMER': 1, 'BILLY': 1, 'KID': 1, 'WINTER': 1, 'KING': 1, '5È': 1, 'RANG': 1, 'HARRY': 1, 'WILD': 1, 'VIGILANTE': 1, 'BROS': 1, 'DNA': 1, 'DO': 1, 'CRIME': 1, 'SUBURRÆTERNA': 1, 'DEUTSCHES': 1, 'HAUS': 1, 'INFORMACJA': 1, 'ZWROTNA': 1, 'SAHSIYET': 1, 'LAZARUS': 1, 'PROJECT': 1, 'LE': 1, 'VOYAGEUR': 1, 'TERROR': 1, 'LAKE': 1, 'DRIVE': 1, 'CROWN': 1, 'PROFESSORE': 1, 'HEARTBEATS': 1, 'OJITOS': 1, 'HUEVO': 1, 'SAGRADA': 1, 'FAMILIA': 1, 'SORT': 1, 'EN': 1, 'HELT': 1, 'VANLIG': 1, 'FAMILJ': 1, 'DOCTOR': 1, 'WHO': 1, '(2005)': 1, 'ARTFUL': 1, 'DODGER': 1}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# REFACTO FUNCTIONS\n",
    "def count(property_name, reverse = True, sort = True):\n",
    "    counts = {}\n",
    "    for element in property_name:\n",
    "        if element in counts:\n",
    "            counts[element] += 1\n",
    "        else:\n",
    "            counts[element] = 1\n",
    "    if sort == True:\n",
    "        return dict(sorted(counts.items(), key=lambda item: item[1], reverse=reverse))\n",
    "    else:\n",
    "        return counts\n",
    "    \n",
    "def get_page_content(year_month = \"\", end_point = \"\", ):\n",
    "    url = f\"https://www.spin-off.fr/{end_point}?date={year_month}\" if year_month else f\"https://www.spin-off.fr/{end_point}\"\n",
    "\n",
    "    # Request Content\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "\n",
    "    # Parse HTML\n",
    "    return BeautifulSoup(content, features=\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# 1️⃣ Récupérer les données relatives à la diffusion d’épisodes pour le mois en cours disponibles sur cette page :  \n",
    "def get_series(year_month = \"\"):\n",
    "    # Parse HTML\n",
    "    page = get_page_content(year_month, \"calendrier_des_series.html\")\n",
    "\n",
    "    list_of_series = [serie_name for serie_name in page.find_all('span',class_=['calendrier_episodes'])]\n",
    "\n",
    "    # Le nom de la série\n",
    "    list_of_series_name = [serie_name.find_all(\"a\")[0].text for serie_name in list_of_series]\n",
    "\n",
    "    # Le numéro de l’épisode\n",
    "    list_of_series_episode = [serie_episode.find_all(\"a\")[1].text.split(\".\")[1] for serie_episode in list_of_series]\n",
    "\n",
    "    # Le numéro de la saison\n",
    "    list_of_series_season = [serie_season.find_all(\"a\")[1].text.split(\".\")[0] for serie_season in list_of_series]\n",
    "\n",
    "    # La date de diffusion de l’épisode\n",
    "    list_of_series_date = [serie_date.find_previous_sibling(\"div\").get(\"id\").strip(\"jour_\") for serie_date in list_of_series]\n",
    "\n",
    "    # Le pays d’origine\n",
    "    list_of_series_origin = [serie_origin.find_previous_sibling().find_previous_sibling().get(\"alt\") for serie_origin in list_of_series]\n",
    "\n",
    "    # La chaîne qui diffuse la série\n",
    "    list_of_series_channel = [serie_channel.find_previous_sibling().get(\"alt\") for serie_channel in list_of_series]\n",
    "\n",
    "    # L’url relative de la page de l’épisode sur le site spin-off \n",
    "    # (par exemple : episode01-408094-01102023-saison14-Bob-s-Burgers.html)\n",
    "    list_of_series_url = [serie_url.find_all(\"a\")[1].get('href') for serie_url in list_of_series]\n",
    "\n",
    "    return {\n",
    "        \"nom_serie\": list_of_series_name, \n",
    "        \"numero_de_lepisode\": list_of_series_episode, \n",
    "        \"numero_de_la_saison\": list_of_series_season, \n",
    "        \"date_de_diffusion_de_lepisode\": list_of_series_date, \n",
    "        \"pays_d_origine\": list_of_series_origin, \n",
    "        \"chaine_de_diffusion\": list_of_series_channel, \n",
    "        \"url_relative_de_lepisode\": list_of_series_url\n",
    "    }\n",
    "    \n",
    "# print(get_series())\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# 1️⃣ Enregistrez ces données dans un fichier episodes.csv dans le dossier data/files (vous pouvez utiliser une librairie) :\n",
    "def create_episode_csv(data):\n",
    "    header = [key for key in data]    \n",
    "    data_values = [data[key] for key in data]\n",
    "    \n",
    "    rows = []\n",
    "    # On parcourt la liste (sachant que chaque liste a la même longueur)\n",
    "    for column in range(len(data_values[0])):\n",
    "        row = []\n",
    "        for index in range(len(data_values)):\n",
    "            row.append(data_values[index][column])\n",
    "        rows.append(row)\n",
    "        \n",
    "    with open('data/files/episodes.csv', 'w+') as file:\n",
    "        file.write(\",\".join(header))\n",
    "        for row in rows:\n",
    "            file.write(\"\\n\" + \",\".join(row))\n",
    "            \n",
    "# create_episode_csv(get_series())\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# 3️⃣ Écrire une fonction ou une classe qui permet de lire le fichier episodes.csv sans utiliser de librairie. Cette fonction ou classe devra renvoyer une liste de tuples avec les bons types : \n",
    "def read_episodes_csv():       \n",
    "    with open('data/files/episodes.csv', 'r') as file:\n",
    "        content = file.read()\n",
    "        typed_content = []\n",
    "        for serie in content.split(\"\\n\")[1:]:\n",
    "            serie_elements = serie.split(\",\")            \n",
    "            \n",
    "            # Épisodes\n",
    "            if serie_elements[1]:\n",
    "                if serie_elements[1].isalpha():\n",
    "                    serie_elements[1] = -1\n",
    "                else:\n",
    "                    serie_elements[1] = (int(serie_elements[1]))\n",
    "                    \n",
    "            # Saisons  \n",
    "            if serie_elements[2]:\n",
    "                if serie_elements[2].isalpha():\n",
    "                    serie_elements[2] = 0\n",
    "                else:\n",
    "                    serie_elements[2] = (int(serie_elements[2]))\n",
    "                    \n",
    "            # Date de diffusion  \n",
    "            if serie_elements[3]:\n",
    "                serie_date = serie_elements[3].split(\"-\")\n",
    "                year = int(serie_date[2])\n",
    "                month = int(serie_date[1])\n",
    "                day = int(serie_date[0])\n",
    "                serie_elements[3] = date(year, month, day)\n",
    "                    \n",
    "            typed_content.append(tuple(serie_row for serie_row in serie_elements))\n",
    "        return typed_content\n",
    "            \n",
    "# print(read_episodes_csv())\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# SQL [1/2]\n",
    "# 2️⃣ Insérer les données de la question Scraping [1/2] dans base de données sqlite appelée database.db dans le dossier data/databases. La table devra s’appeler episode .\n",
    "# Veillez à utiliser les types adéquats (la date peut toutefois être stockée en tant que chaîne de caractères avec un typeTEXT).\n",
    "def episodes_to_database():\n",
    "    # Connexion à la base de données (si elle n'existe pas, elle sera créée)\n",
    "    conn = sqlite3.connect('data/databases/database.db')\n",
    "\n",
    "    # Création d'un curseur pour exécuter des commandes SQL\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Définir le schéma de la table\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS episode (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            nom_serie TEXT,\n",
    "            numero_episode INTEGER,\n",
    "            numero_saison INTEGER,\n",
    "            date_diffusion DATE,\n",
    "            pays_origine TEXT,\n",
    "            chaine_diffusion TEXT,\n",
    "            url_episode TEXT\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Insérer les données\n",
    "    cur.executemany(\"\"\"INSERT INTO episode \n",
    "                    (\n",
    "                        nom_serie,\n",
    "                        numero_episode,\n",
    "                        numero_saison,\n",
    "                        date_diffusion,\n",
    "                        pays_origine,\n",
    "                        chaine_diffusion,\n",
    "                        url_episode\n",
    "                    ) VALUES (?,?,?,?,?,?,?)\"\"\",\n",
    "                    read_episodes_csv())\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Décommenter ci-dessous pour tester la lecture\n",
    "    cur.execute(\"SELECT * FROM episode\")\n",
    "    resultats = cur.fetchall()\n",
    "    for row in resultats:\n",
    "        print(row)\n",
    "\n",
    "# episodes_to_database()\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# Algorithmie [1/2]\n",
    "# 3️⃣ Calculer le nombre d’épisodes diffusés par chaque chaîne de télévision (présente dans les données) en Octobre.\n",
    "# property_name → \"nom_serie\", \"numero_de_lepisode\", \"numero_de_la_saison\", \"date_de_diffusion_de_lepisode\", \"pays_d_origine\", \"chaine_de_diffusion\", \"url_relative_de_lepisode\"\n",
    "def count_episodes_by_property(year_month, property_name):\n",
    "    properties = get_series(year_month)[property_name]\n",
    "    return count(properties)\n",
    "\n",
    "# print(count_episodes_by_property(\"2023-10\", \"chaine_de_diffusion\"))\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# Vous pouvez faire directement des requêtes SQL, ou rapatrier les données depuis une table (ou un fichier dans lequel vous les auriez stocker) et faire les calculs avec Python. \n",
    "# Indiquer dans le fichier README.md le nom des trois chaînes qui ont diffusé le plus d’épisodes. \n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# 3️⃣ Faire de même pour les pays (pensez à mutualiser votre code !)\n",
    "# print(count_episodes_by_property(\"2023-10\", \"pays_d_origine\"))\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# 3️⃣ Quels mots reviennent le plus souvent dans les noms des séries ? (attention à ne compter qu’une seule fois chaque série, et pas une fois chaque épisode)\n",
    "# Les indiquer dans le fichier README.md\n",
    "def most_used_word_in_show_title(year_month):\n",
    "    shows_title = [key for key in count_episodes_by_property(year_month, \"nom_serie\")]\n",
    "    words = []\n",
    "    for show_title in shows_title:\n",
    "        for word in show_title.split(\" \"):\n",
    "            words.append(word.upper())\n",
    "    \n",
    "    return count(words)\n",
    "\n",
    "print(most_used_word_in_show_title(\"2023-11\"))\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# Scraping [2/2] \n",
    "# 4️⃣ Sur les pages individuelles des épisodes (dont l’url à été récupérée lors de la première question), récupérer la durée de l’épisode. Les requêtes peuvent être un peu longue donc vous pouvez ne le faire que pour une seule chaîne comme Apple TV. Veiller à ne pas perdre les données pour pouvoir les insérer dans SQL. Pensez à utiliser un time.sleep entre les requêtes.\n",
    "def get_episodes_duration():\n",
    "    # Connexion à la base de données (si elle n'existe pas, elle sera créée)\n",
    "    conn = sqlite3.connect('data/databases/database.db')\n",
    "\n",
    "    # Création d'un curseur pour exécuter des commandes SQL\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"SELECT * FROM episode WHERE chaine_diffusion LIKE 'Apple TV+'\")\n",
    "    series = cur.fetchall()\n",
    "\n",
    "    durations = []\n",
    "    for serie in series:    \n",
    "        page = get_page_content(False, serie[7])\n",
    "        duration = page.find('div', class_='episode_infos_episode_format').text.replace(\"minutes\", \"\").strip()\n",
    "        \n",
    "        if duration != \"\":\n",
    "            durations.append([serie[0], int(duration)])\n",
    "        else:\n",
    "            durations.append([serie[0], 0])\n",
    "        time.sleep(1)\n",
    "\n",
    "    return durations\n",
    "        \n",
    "# print(get_episodes_duration())\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# SQL [2/2]\n",
    "# 4️⃣ Stocker les données de durée d’épisode (en minutes) dans une nouvelles table duration qui contiendra une Foreign Key pointant sur l’épisode en question dans la table episode \n",
    "def save_duration_to_database(data):\n",
    "    # Connexion à la base de données (si elle n'existe pas, elle sera créée)\n",
    "    conn = sqlite3.connect('data/databases/database.db')\n",
    "\n",
    "    # Création d'un curseur pour exécuter des commandes SQL\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Create Table Schema\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS duration (\n",
    "            id   INTEGER PRIMARY KEY,\n",
    "            duration INTEGER,\n",
    "            duration_id INTEGER,\n",
    "            FOREIGN KEY (duration_id)\n",
    "                REFERENCES episode (id) \n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Insert Data\n",
    "    cur.executemany(\"\"\"INSERT INTO duration \n",
    "                    (\n",
    "                        duration_id,\n",
    "                        duration\n",
    "                    ) VALUES (?,?)\"\"\",\n",
    "                    data)\n",
    "    conn.commit()\n",
    "    \n",
    "# save_duration_to_database(get_episodes_duration())\n",
    "# *************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************\n",
    "# Algorithmie [2/2]\n",
    "# 5️⃣ Quelle est la chaîne de TV qui diffuse des épisodes pendant le plus grand nombre de jours consécutifs sur le mois d’Octobre ? (écrire une fonction qui permet de répondre à cet question)\n",
    "def most_diffused_channel(year_month):\n",
    "    page = get_page_content(year_month, \"calendrier_des_series.html\")\n",
    "\n",
    "    list_of_channels_by_day = [[key for key in count([channel.find_previous_sibling(\"img\").get(\"alt\") for channel in serie_name.find_all(\"span\", class_=\"calendrier_episodes\")], False, False)] for serie_name in page.find_all('td',class_=['td_jour']) if serie_name.find(\"div\", class_=\"div_jour\")]\n",
    "\n",
    "    all_channels_of_the_month = []\n",
    "    for list_of_channels_of_the_day in list_of_channels_by_day:\n",
    "        for channel_of_the_day in list_of_channels_of_the_day:\n",
    "            all_channels_of_the_month.append(channel_of_the_day)\n",
    "            \n",
    "    all_channels_keyname = [key for key in count(all_channels_of_the_month, False, False)]\n",
    "            \n",
    "    counter_final = {}\n",
    "    counter_tmp = {}\n",
    "    \n",
    "    # Initiate all channels at 0\n",
    "    for channel in all_channels_keyname:\n",
    "        counter_final[channel] = 0\n",
    "        counter_tmp[channel] = 0\n",
    "        \n",
    "    # Begin counter\n",
    "    for list_of_channels_of_the_day in list_of_channels_by_day:\n",
    "        counter = {channel_of_the_day: 0 for channel_of_the_day in list_of_channels_of_the_day}\n",
    "        for channel in all_channels_keyname:        \n",
    "            if channel in list_of_channels_of_the_day:\n",
    "                counter_tmp[channel] += 1\n",
    "                if counter_tmp[channel] > counter_final[channel]:\n",
    "                    counter_final[channel] = counter_tmp[channel]\n",
    "            else:\n",
    "                counter_tmp[channel] = 0\n",
    "     \n",
    "    # print(dict(sorted(counter_tmp.items(), key=lambda item: item[1], reverse=True)))\n",
    "    return dict(sorted(counter_final.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# print(most_diffused_channel(\"2023-10\"))\n",
    "# *************************************************\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
